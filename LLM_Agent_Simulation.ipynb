{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================================================\n# 0. INSTALL (KAGGLE SAFE)\n# =========================================================\n!pip install -q transformers accelerate\n\n# =========================================================\n# 1. IMPORTS\n# =========================================================\nimport torch\nimport pandas as pd\nfrom collections import deque\nimport re\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# =========================================================\n# 2. GPU CHECK\n# =========================================================\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NO GPU\")\n\n# =========================================================\n# 3. GAME CONSTANTS\n# =========================================================\nWEEKS = list(range(1, 16))\nPLAYERS = [\"Retailer\", \"Wholesaler\", \"Distributor\", \"Factory\"]\n\nDEMAND = {\n    1: 15, 2: 15, 3: 15, 4: 15,\n    5: 25, 6: 25, 7: 25, 8: 80,\n    9: 30, 10: 18, 11: 12, 12: 22,\n    13: 35, 14: 18, 15: 16\n}\n\nINITIAL_INVENTORY = 15\n\nSCENARIOS = {\n    \"baseline\": {\"shipping_delay\": 2},\n    \"info_share\": {\"shipping_delay\": 2},\n    \"lean\": {\"shipping_delay\": 0},\n    \"lean_info_share\": {\"shipping_delay\": 0},\n}\n\n# =========================================================\n# 4. BEER GAME ENVIRONMENT (WITH HISTORY)\n# =========================================================\nclass BeerGameEnv:\n    def __init__(self, shipping_delay):\n        self.inventory = {p: INITIAL_INVENTORY for p in PLAYERS}\n        self.backlog = {p: 0 for p in PLAYERS}\n        self.orders = {p: [] for p in PLAYERS}\n\n        self.inventory_hist = {p: [] for p in PLAYERS}\n        self.backlog_hist = {p: [] for p in PLAYERS}\n\n        self.pipeline = (\n            {p: deque([INITIAL_INVENTORY] * shipping_delay) for p in PLAYERS}\n            if shipping_delay > 0 else None\n        )\n\n    def receive_shipments(self):\n        if self.pipeline:\n            for p in PLAYERS:\n                self.inventory[p] += self.pipeline[p].popleft()\n\n    def fulfill_demand(self, observed):\n        for p in PLAYERS:\n            total = observed[p] + self.backlog[p]\n            shipped = min(self.inventory[p], total)\n            self.inventory[p] -= shipped\n            self.backlog[p] = total - shipped\n\n            self.inventory_hist[p].append(self.inventory[p])\n            self.backlog_hist[p].append(self.backlog[p])\n\n    def place_orders(self, decisions):\n        for p in PLAYERS:\n            order = max(0, int(decisions[p]))\n            self.orders[p].append(order)\n            if self.pipeline:\n                self.pipeline[p].append(order)\n\n# =========================================================\n# 5. LOAD LLM\n# =========================================================\nMODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nprint(\"Model loaded on:\", model.device)\n\n# =========================================================\n# 6. DECISION PARSER (STABLE)\n# =========================================================\ndef llm_decide(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=60,\n        do_sample=True,\n        temperature=0.75,   # calm variability\n        top_p=0.95\n    )\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    match = re.search(r\"Order\\s*=\\s*(\\d+)\", text)\n    if match:\n        return int(match.group(1))\n    return 0\n\n# =========================================================\n# 7. CALM HUMAN PROMPT (BOUNDED RATIONALITY)\n# =========================================================\ndef llm_agent(player, inventory, backlog, incoming, observed):\n    prompt = f\"\"\"\nYou are a human player participating in the Beer Game as the {player}.\n\nYou do not know future customer demand.\nYou have limited understanding of delays and system-wide effects.\nYou try to make reasonable decisions based on recent observations.\n\nYour goal is to:\n- Meet incoming demand as well as possible\n- Avoid excessive backlog\n- Avoid holding extremely high inventory\n\nCurrent situation:\nInventory: {inventory}\nBacklog: {backlog}\nIncoming shipment next week: {incoming}\nOrder received this week: {observed}\n\nGuidelines:\n- If backlog is increasing, you may increase orders gradually.\n- If inventory is high and backlog is low, you may reduce orders.\n- Avoid extreme overreaction unless the situation clearly worsens.\n\nRespond ONLY in this format:\nOrder = <number>\n\"\"\"\n    return llm_decide(prompt)\n\n# =========================================================\n# 8. RUN ONE SCENARIO\n# =========================================================\ndef run_llm_scenario(scenario_name):\n    shipping_delay = SCENARIOS[scenario_name][\"shipping_delay\"]\n    env = BeerGameEnv(shipping_delay)\n    last_orders = {p: INITIAL_INVENTORY for p in PLAYERS}\n\n    for week in WEEKS:\n        env.receive_shipments()\n\n        observed = {}\n        for i, p in enumerate(PLAYERS):\n            if p == \"Retailer\":\n                observed[p] = DEMAND[week]\n            else:\n                observed[p] = last_orders[PLAYERS[i - 1]]\n\n        env.fulfill_demand(observed)\n\n        decisions = {}\n        for p in PLAYERS:\n            incoming = env.pipeline[p][0] if env.pipeline else 0\n            decisions[p] = llm_agent(\n                p,\n                env.inventory[p],\n                env.backlog[p],\n                incoming,\n                observed[p]\n            )\n\n        env.place_orders(decisions)\n        last_orders = decisions.copy()\n\n    return env\n\n# =========================================================\n# 9. RUN ALL SCENARIOS + SAVE\n# =========================================================\nresults = {}\n\nfor scenario in SCENARIOS:\n    print(f\"Running scenario: {scenario}\")\n    env = run_llm_scenario(scenario)\n    results[scenario] = env\n\n    rows = []\n    for p in PLAYERS:\n        for w in range(len(env.orders[p])):\n            rows.append({\n                \"Scenario\": scenario,\n                \"Week\": w + 1,\n                \"Player\": p,\n                \"Order\": env.orders[p][w],\n                \"Inventory\": env.inventory_hist[p][w],\n                \"Backlog\": env.backlog_hist[p][w]\n            })\n\n    df = pd.DataFrame(rows)\n    df.to_excel(f\"LLM_Beer_Game_{scenario}_CALM.xlsx\", index=False)\n\nprint(\"All CALM-HUMAN scenarios completed and saved.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}